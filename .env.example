# ============================================================================
# AI Provider API Keys
# ============================================================================

# Primary Provider: Google Gemini (FREE - Unlimited for our use case)
GEMINI_API_KEY=your_gemini_api_key_here

# Secondary Provider: Groq (FREE - Ultra-fast inference)
GROQ_API_KEY=your_groq_api_key_here

# Tertiary Provider: Anthropic Claude (PAID - Last resort only)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ============================================================================
# Model Configuration
# ============================================================================

# Gemini Settings (Primary)
GEMINI_MODEL=gemini-1.5-flash
GEMINI_TEMPERATURE=0.1
GEMINI_MAX_TOKENS=4000

# Groq Settings (Secondary)
GROQ_MODEL=llama-3.1-70b-versatile
GROQ_TEMPERATURE=0.1
GROQ_MAX_TOKENS=4000

# Claude Settings (Tertiary - Cost-controlled)
CLAUDE_MODEL=claude-sonnet-4-20250514
CLAUDE_TEMPERATURE=0.1
CLAUDE_MAX_TOKENS=4000

# ============================================================================
# Cost Control & Limits
# ============================================================================

# Claude Usage Limits (to prevent unexpected costs)
CLAUDE_DAILY_LIMIT_USD=5.00          # Max $5 per day
CLAUDE_MONTHLY_LIMIT_USD=50.00       # Max $50 per month
CLAUDE_COST_PER_1K_INPUT=0.003       # $3 per million input tokens
CLAUDE_COST_PER_1K_OUTPUT=0.015      # $15 per million output tokens

# Alert thresholds (percentage of limit)
COST_WARNING_THRESHOLD=0.75          # Warn at 75% of limit
COST_CRITICAL_THRESHOLD=0.90         # Critical alert at 90%

# ============================================================================
# Provider Priority & Fallback Strategy
# ============================================================================

# Provider order (comma-separated, will try in order)
PROVIDER_PRIORITY=gemini,groq,claude

# Confidence threshold to trigger fallback (0.0-1.0)
MIN_CONFIDENCE_THRESHOLD=0.80

# Enable automatic fallback on low confidence
AUTO_FALLBACK_ENABLED=true

# ============================================================================
# Caching Configuration
# ============================================================================

# Enable persistent caching to avoid re-processing
CACHE_ENABLED=true
CACHE_DIR=.cache/extractions
CACHE_TTL_DAYS=30                    # Cache validity period

# ============================================================================
# Retry & Rate Limiting
# ============================================================================

# Retry configuration
MAX_RETRIES_PER_PROVIDER=3
RETRY_BACKOFF_BASE=1                 # Base delay in seconds (exponential: 1s, 2s, 4s)

# Rate limiting (requests per minute)
GEMINI_RPM_LIMIT=15                  # Free tier limit
GROQ_RPM_LIMIT=6000                  # Very high limit
CLAUDE_RPM_LIMIT=50                  # Conservative to control costs

# ============================================================================
# Monitoring & Logging
# ============================================================================

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Enable detailed provider performance logging
ENABLE_PERFORMANCE_LOGGING=true

# Usage tracking database
USAGE_DB_PATH=.monitoring/usage.db

# Generate daily usage reports
DAILY_REPORT_ENABLED=true
REPORT_EMAIL=your_email@example.com  # Optional: email for alerts

# ============================================================================
# Feature Flags
# ============================================================================

# Enable validation layer (recommended)
ENABLE_VALIDATION=true

# Enable health monitoring
ENABLE_HEALTH_MONITORING=true

# A/B testing mode (randomly select provider for comparison)
AB_TESTING_MODE=false

# ============================================================================
# Advanced Settings
# ============================================================================

# Context window optimization
AUTO_CHUNK_LARGE_DOCUMENTS=true
MAX_CONTEXT_LENGTH=100000            # Characters

# Parallel processing
MAX_CONCURRENT_REQUESTS=3

# Development mode (uses mock responses, no API calls)
DEV_MODE=false
